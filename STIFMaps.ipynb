{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee7eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy import interpolate\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20efa19",
   "metadata": {},
   "source": [
    "# Provide directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f999c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected that the staining_dir has input files for DAPI, GFP, mask, stain1, and stain2\n",
    "staining_dir = '/media/user/Extreme SSD/Staining/norwegian/publication_inputs/'\n",
    "npy_dir = '/media/user/Extreme SSD/Staining/norwegian/publication_npy/'\n",
    "out_dir = '/media/user/Extreme SSD/Staining/norwegian/publication_out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "555a8c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the models to use\n",
    "models = ['/home/user/Documents/STIFMap_publication_code/STIFMaps/trained_models/iteration_1010.pt',\n",
    "          '/home/user/Documents/STIFMap_publication_code/STIFMaps/trained_models/iteration_1011.pt',\n",
    "          '/home/user/Documents/STIFMap_publication_code/STIFMaps/trained_models/iteration_1012.pt',\n",
    "          '/home/user/Documents/STIFMap_publication_code/STIFMaps/trained_models/iteration_1013.pt',\n",
    "          '/home/user/Documents/STIFMap_publication_code/STIFMaps/trained_models/iteration_1014.pt'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e9ef6c",
   "metadata": {},
   "source": [
    "# Define functions used below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "613d55f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize an image from 0-1\n",
    "def norm_pic(im):\n",
    "    # Find the thresholds\n",
    "    hmin = np.quantile(im.flatten(), .01)\n",
    "    hmax = np.quantile(im.flatten(), .99)\n",
    "\n",
    "    # Create the new thresholded image\n",
    "    im2 = (im - hmin) / (hmax-hmin)\n",
    "    im2 = np.clip(im2, 0, 1)\n",
    "    \n",
    "    return im2\n",
    "\n",
    "# Given the step size between squares and the scale factor between the input\n",
    "#      image and the training data, find the actual step size to use in the input image\n",
    "#      Note that the output step size must be an even number \n",
    "def get_step(step, scale_factor):\n",
    "    step = step / scale_factor\n",
    "\n",
    "    if round(step) % 2 == 0:\n",
    "        return round(step)\n",
    "    elif round(step) == int(step):\n",
    "        return round(step)+1\n",
    "    else:\n",
    "        return int(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e6c733",
   "metadata": {},
   "source": [
    "# Specify Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6d92a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step size is 22 pixels\n",
      "Half step is 11 pixels\n",
      "Side length for a square is 124 pixels\n",
      "Half side length is 62 pixels\n"
     ]
    }
   ],
   "source": [
    "# Scale factor to convert from HER2 slide scans to training data resolution\n",
    "scale_factor = 1.8025\n",
    "\n",
    "# The step size to use from one square to the next\n",
    "step = 40\n",
    "\n",
    "# How many squares to evaluate at once with the network\n",
    "batch_size = 100\n",
    "\n",
    "# The pixel threshold to use when comparing STIFMaps/DAPI/GFP vs stain intensity\n",
    "quantile = .99\n",
    "\n",
    "# used to downsample images if the full images use too much memory\n",
    "scale_percent = 100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get the actual step size given the scale_factor\n",
    "step = get_step(step, scale_factor)\n",
    "# and the half step size\n",
    "half_step = int(step/2)\n",
    "\n",
    "print('Step size is ' + str(step) + ' pixels')\n",
    "print('Half step is ' + str(half_step) + ' pixels')\n",
    "\n",
    "# Get the actual side length of one square\n",
    "square_side = get_step(224, scale_factor)\n",
    "# and the half side length\n",
    "half_side = int(square_side/2)\n",
    "\n",
    "print('Side length for a square is ' + str(square_side) + ' pixels')\n",
    "print('Half side length is ' + str(half_side) + ' pixels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133ef4ab",
   "metadata": {},
   "source": [
    "# Organize the input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a48d3198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>dapi_file</th>\n",
       "      <th>gfp_file</th>\n",
       "      <th>mask_file</th>\n",
       "      <th>stain1_file</th>\n",
       "      <th>stain2_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0040</td>\n",
       "      <td>0040_DAPI.TIF</td>\n",
       "      <td>0040_GFP.TIF</td>\n",
       "      <td>0040_MASK.TIF</td>\n",
       "      <td>0040_ZEB1.TIF</td>\n",
       "      <td>0040_HER2.TIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0048</td>\n",
       "      <td>0048_DAPI.TIF</td>\n",
       "      <td>0048_GFP.TIF</td>\n",
       "      <td>0048_MASK.TIF</td>\n",
       "      <td>0048_ZEB1.TIF</td>\n",
       "      <td>0048_HER2.TIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0053-2</td>\n",
       "      <td>0053-2_DAPI.TIF</td>\n",
       "      <td>0053-2_GFP.TIF</td>\n",
       "      <td>0053-2_MASK.TIF</td>\n",
       "      <td>0053-2_ZEB1.TIF</td>\n",
       "      <td>0053-2_HER2.TIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0053</td>\n",
       "      <td>0053_DAPI.TIF</td>\n",
       "      <td>0053_GFP.TIF</td>\n",
       "      <td>0053_MASK.TIF</td>\n",
       "      <td>0053_ZEB1.TIF</td>\n",
       "      <td>0053_HER2.TIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0069</td>\n",
       "      <td>0069_DAPI.TIF</td>\n",
       "      <td>0069_GFP.TIF</td>\n",
       "      <td>0069_MASK.TIF</td>\n",
       "      <td>0069_ZEB1.TIF</td>\n",
       "      <td>0069_HER2.TIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6450</td>\n",
       "      <td>6450_DAPI.TIF</td>\n",
       "      <td>6450_GFP.TIF</td>\n",
       "      <td>6450_MASK.TIF</td>\n",
       "      <td>6450_ZEB1.TIF</td>\n",
       "      <td>6450_HER2.TIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6748-2</td>\n",
       "      <td>6748-2_DAPI.TIF</td>\n",
       "      <td>6748-2_GFP.TIF</td>\n",
       "      <td>6748-2_MASK.TIF</td>\n",
       "      <td>6748-2_ZEB1.TIF</td>\n",
       "      <td>6748-2_HER2.TIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6748</td>\n",
       "      <td>6748_DAPI.TIF</td>\n",
       "      <td>6748_GFP.TIF</td>\n",
       "      <td>6748_MASK.TIF</td>\n",
       "      <td>6748_ZEB1.TIF</td>\n",
       "      <td>6748_HER2.TIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6930</td>\n",
       "      <td>6930_DAPI.TIF</td>\n",
       "      <td>6930_GFP.TIF</td>\n",
       "      <td>6930_MASK.TIF</td>\n",
       "      <td>6930_ZEB1.TIF</td>\n",
       "      <td>6930_HER2.TIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7126</td>\n",
       "      <td>7126_DAPI.TIF</td>\n",
       "      <td>7126_GFP.TIF</td>\n",
       "      <td>7126_MASK.TIF</td>\n",
       "      <td>7126_ZEB1.TIF</td>\n",
       "      <td>7126_HER2.TIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7334-2</td>\n",
       "      <td>7334-2_DAPI.TIF</td>\n",
       "      <td>7334-2_GFP.TIF</td>\n",
       "      <td>7334-2_MASK.TIF</td>\n",
       "      <td>7334-2_ZEB1.TIF</td>\n",
       "      <td>7334-2_HER2.TIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7334</td>\n",
       "      <td>7334_DAPI.TIF</td>\n",
       "      <td>7334_GFP.TIF</td>\n",
       "      <td>7334_MASK.TIF</td>\n",
       "      <td>7334_ZEB1.TIF</td>\n",
       "      <td>7334_HER2.TIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7347-2</td>\n",
       "      <td>7347-2_DAPI.TIF</td>\n",
       "      <td>7347-2_GFP.TIF</td>\n",
       "      <td>7347-2_MASK.TIF</td>\n",
       "      <td>7347-2_ZEB1.TIF</td>\n",
       "      <td>7347-2_HER2.TIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7347</td>\n",
       "      <td>7347_DAPI.TIF</td>\n",
       "      <td>7347_GFP.TIF</td>\n",
       "      <td>7347_MASK.TIF</td>\n",
       "      <td>7347_ZEB1.TIF</td>\n",
       "      <td>7347_HER2.TIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7360</td>\n",
       "      <td>7360_DAPI.TIF</td>\n",
       "      <td>7360_GFP.TIF</td>\n",
       "      <td>7360_MASK.TIF</td>\n",
       "      <td>7360_ZEB1.TIF</td>\n",
       "      <td>7360_HER2.TIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7364</td>\n",
       "      <td>7364_DAPI.TIF</td>\n",
       "      <td>7364_GFP.TIF</td>\n",
       "      <td>7364_MASK.TIF</td>\n",
       "      <td>7364_ZEB1.TIF</td>\n",
       "      <td>7364_HER2.TIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7379</td>\n",
       "      <td>7379_DAPI.TIF</td>\n",
       "      <td>7379_GFP.TIF</td>\n",
       "      <td>7379_MASK.TIF</td>\n",
       "      <td>7379_ZEB1.TIF</td>\n",
       "      <td>7379_HER2.TIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7406</td>\n",
       "      <td>7406_DAPI.TIF</td>\n",
       "      <td>7406_GFP.TIF</td>\n",
       "      <td>7406_MASK.TIF</td>\n",
       "      <td>7406_ZEB1.TIF</td>\n",
       "      <td>7406_HER2.TIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7417</td>\n",
       "      <td>7417_DAPI.TIF</td>\n",
       "      <td>7417_GFP.TIF</td>\n",
       "      <td>7417_MASK.TIF</td>\n",
       "      <td>7417_ZEB1.TIF</td>\n",
       "      <td>7417_HER2.TIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7428</td>\n",
       "      <td>7428_DAPI.TIF</td>\n",
       "      <td>7428_GFP.TIF</td>\n",
       "      <td>7428_MASK.TIF</td>\n",
       "      <td>7428_ZEB1.TIF</td>\n",
       "      <td>7428_HER2.TIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7619</td>\n",
       "      <td>7619_DAPI.TIF</td>\n",
       "      <td>7619_GFP.TIF</td>\n",
       "      <td>7619_MASK.TIF</td>\n",
       "      <td>7619_ZEB1.TIF</td>\n",
       "      <td>7619_HER2.TIF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name        dapi_file        gfp_file        mask_file      stain1_file  \\\n",
       "0     0040    0040_DAPI.TIF    0040_GFP.TIF    0040_MASK.TIF    0040_ZEB1.TIF   \n",
       "1     0048    0048_DAPI.TIF    0048_GFP.TIF    0048_MASK.TIF    0048_ZEB1.TIF   \n",
       "2   0053-2  0053-2_DAPI.TIF  0053-2_GFP.TIF  0053-2_MASK.TIF  0053-2_ZEB1.TIF   \n",
       "3     0053    0053_DAPI.TIF    0053_GFP.TIF    0053_MASK.TIF    0053_ZEB1.TIF   \n",
       "4     0069    0069_DAPI.TIF    0069_GFP.TIF    0069_MASK.TIF    0069_ZEB1.TIF   \n",
       "5     6450    6450_DAPI.TIF    6450_GFP.TIF    6450_MASK.TIF    6450_ZEB1.TIF   \n",
       "6   6748-2  6748-2_DAPI.TIF  6748-2_GFP.TIF  6748-2_MASK.TIF  6748-2_ZEB1.TIF   \n",
       "7     6748    6748_DAPI.TIF    6748_GFP.TIF    6748_MASK.TIF    6748_ZEB1.TIF   \n",
       "8     6930    6930_DAPI.TIF    6930_GFP.TIF    6930_MASK.TIF    6930_ZEB1.TIF   \n",
       "9     7126    7126_DAPI.TIF    7126_GFP.TIF    7126_MASK.TIF    7126_ZEB1.TIF   \n",
       "10  7334-2  7334-2_DAPI.TIF  7334-2_GFP.TIF  7334-2_MASK.TIF  7334-2_ZEB1.TIF   \n",
       "11    7334    7334_DAPI.TIF    7334_GFP.TIF    7334_MASK.TIF    7334_ZEB1.TIF   \n",
       "12  7347-2  7347-2_DAPI.TIF  7347-2_GFP.TIF  7347-2_MASK.TIF  7347-2_ZEB1.TIF   \n",
       "13    7347    7347_DAPI.TIF    7347_GFP.TIF    7347_MASK.TIF    7347_ZEB1.TIF   \n",
       "14    7360    7360_DAPI.TIF    7360_GFP.TIF    7360_MASK.TIF    7360_ZEB1.TIF   \n",
       "15    7364    7364_DAPI.TIF    7364_GFP.TIF    7364_MASK.TIF    7364_ZEB1.TIF   \n",
       "16    7379    7379_DAPI.TIF    7379_GFP.TIF    7379_MASK.TIF    7379_ZEB1.TIF   \n",
       "17    7406    7406_DAPI.TIF    7406_GFP.TIF    7406_MASK.TIF    7406_ZEB1.TIF   \n",
       "18    7417    7417_DAPI.TIF    7417_GFP.TIF    7417_MASK.TIF    7417_ZEB1.TIF   \n",
       "19    7428    7428_DAPI.TIF    7428_GFP.TIF    7428_MASK.TIF    7428_ZEB1.TIF   \n",
       "20    7619    7619_DAPI.TIF    7619_GFP.TIF    7619_MASK.TIF    7619_ZEB1.TIF   \n",
       "\n",
       "        stain2_file  \n",
       "0     0040_HER2.TIF  \n",
       "1     0048_HER2.TIF  \n",
       "2   0053-2_HER2.TIF  \n",
       "3     0053_HER2.TIF  \n",
       "4     0069_HER2.TIF  \n",
       "5     6450_HER2.TIF  \n",
       "6   6748-2_HER2.TIF  \n",
       "7     6748_HER2.TIF  \n",
       "8     6930_HER2.TIF  \n",
       "9     7126_HER2.TIF  \n",
       "10  7334-2_HER2.TIF  \n",
       "11    7334_HER2.TIF  \n",
       "12  7347-2_HER2.TIF  \n",
       "13    7347_HER2.TIF  \n",
       "14    7360_HER2.TIF  \n",
       "15    7364_HER2.TIF  \n",
       "16    7379_HER2.TIF  \n",
       "17    7406_HER2.TIF  \n",
       "18    7417_HER2.TIF  \n",
       "19    7428_HER2.TIF  \n",
       "20    7619_HER2.TIF  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List and sort all files in the staining directory\n",
    "files = os.listdir(staining_dir)\n",
    "files.sort()\n",
    "\n",
    "# Split up the files into their respective lists\n",
    "dapis = files[0::5]\n",
    "gfps = files[1::5]\n",
    "masks = files[3::5]\n",
    "stain1s = files[4::5]\n",
    "stain2s = files[2::5]\n",
    "\n",
    "# Name each sample using the string before the first underscore\n",
    "names = [gfp.split('_')[0] for gfp in gfps]\n",
    "\n",
    "# Create a dataframe of the input files\n",
    "sample_list = pd.DataFrame({\n",
    "    'name':names,\n",
    "    'dapi_file':dapis,\n",
    "    'gfp_file':gfps,\n",
    "    'mask_file':masks,\n",
    "    'stain1_file':stain1s,\n",
    "    'stain2_file':stain2s\n",
    "})\n",
    "\n",
    "# Does this look correct?\n",
    "sample_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11da4c2e",
   "metadata": {},
   "source": [
    "# Load the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f98d8039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1343ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/vision/0.8/_modules/torchvision/models/alexnet.html\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1, dropout: float = 0.5) -> None:\n",
    "        super().__init__()\n",
    "        #_log_api_usage_once(self)\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4f54dc",
   "metadata": {},
   "source": [
    "# Get STIFMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b445de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation to apply to every square; \n",
    "# Resize the square to the appropriate dimensions for the network\n",
    "#      and convert to a tensor\n",
    "valid_transform = transforms.Compose(\n",
    "    [transforms.ToPILImage(),\n",
    "    transforms.Resize(size=(224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Lambda(lambda x: x[0:2]) # Remove the blank channel\n",
    "    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7621cf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0040\n",
      "Image shape is (3, 14742, 3262)\n",
      "Num squares in x direction is 143\n",
      "Num squares in y direction is 665\n",
      "Time taken to predict squares is 109.0371687412262\n",
      "Time taken to predict squares is 219.1393325328827\n",
      "Time taken to predict squares is 329.3038272857666\n",
      "Time taken to predict squares is 440.0370180606842\n",
      "Time taken to predict squares is 550.3157835006714\n",
      "Total time taken is 551.4533696174622\n"
     ]
    }
   ],
   "source": [
    "# For each GFP-DAPI pair, generate the STIFMap for each model provided\n",
    "\n",
    "then = time.time()\n",
    "    \n",
    "for im_num in range(1):#len(gfps)):\n",
    "\n",
    "    name = names[im_num]\n",
    "\n",
    "    print(name)\n",
    "\n",
    "    ############################################ Import the images\n",
    "    dapi = io.imread(staining_dir + dapis[im_num])\n",
    "    gfp = io.imread(staining_dir + gfps[im_num])\n",
    "    mask = io.imread(staining_dir + masks[im_num])\n",
    "\n",
    "    # Normalize the images\n",
    "    dapi = norm_pic(dapi)\n",
    "    gfp = norm_pic(gfp)\n",
    "    # Convert the datatype\n",
    "    dapi = dapi.astype(np.float32)\n",
    "    gfp = gfp.astype(np.float32)\n",
    "\n",
    "    \n",
    "    '''    \n",
    "    ######################### Save the dapi norm pic\n",
    "    #io.imsave(out_dir + name + '_DAPI_norm.TIF', dapi)\n",
    "    ######################### Save the gfp norm pic\n",
    "    #io.imsave(out_dir + name + '_GFP_norm.TIF', gfp)\n",
    "    '''\n",
    "    \n",
    "    # Combine DAPI and GFP into one RGB image with a layer of zeros\n",
    "    blank = np.zeros(shape = gfp.shape, dtype = np.float32)\n",
    "    im = np.stack((gfp,dapi,blank), axis=0)\n",
    "\n",
    "    print('Image shape is ' + str(im.shape))\n",
    "    # Remove the original layers for memory purposes\n",
    "    del dapi\n",
    "    del gfp\n",
    "    del blank\n",
    "\n",
    "    ######################### Split the image into squares\n",
    "    x_range = int((im.shape[2] - square_side) / (step)) + 1\n",
    "    y_range = int((im.shape[1] - square_side) / (step)) + 1\n",
    "\n",
    "    print('Num squares in x direction is ' + str(x_range))\n",
    "    print('Num squares in y direction is ' + str(y_range))\n",
    " \n",
    "    # Generate two lists of the (x,y) indices for every square\n",
    "    x = np.array(list(range(x_range)) * y_range)\n",
    "    y = [[i]*x_range for i in list(range(y_range))]\n",
    "    y = np.array(y)\n",
    "    y = y.flatten()\n",
    "\n",
    "    then2 = time.time()\n",
    "\n",
    "    # Fit the squares with each model\n",
    "    for model in models:\n",
    "        # The iteration number\n",
    "        model_name = model[-7:-3]\n",
    "        \n",
    "        # One list to keep track of input squares to the model\n",
    "        squares = []\n",
    "        # and another to keep track of the model prediction values\n",
    "        outputs = []\n",
    "\n",
    "        # Load the model\n",
    "        network = AlexNet()\n",
    "        network.load_state_dict(torch.load(model))\n",
    "        network.eval()\n",
    "\n",
    "        # Keep track of which values should be masked out\n",
    "        masked_value_tracker = []\n",
    "\n",
    "        # Go through each square one-by-one\n",
    "        for i in range(len(x)):\n",
    "\n",
    "            # Get the current (X,Y) position from the mask\n",
    "            masked_value = mask[step*y[i] + half_side, step*x[i] + half_side]\n",
    "            # and add it to the list\n",
    "            masked_value_tracker.append(masked_value)\n",
    "            \n",
    "            # If a model is outside of the masked region, then we don't want to use it\n",
    "            if masked_value != 0:\n",
    "                # Otherwise, (1) get the square\n",
    "                im_sub = im[:,step*y[i]:step*y[i] + square_side, step*x[i]:step*x[i] + square_side].copy()\n",
    "                # (2) convert to a tensor\n",
    "                im_sub = torch.from_numpy(im_sub)\n",
    "                # (3) transform it to the right dimensions\n",
    "                im_sub = valid_transform(im_sub)\n",
    "                # (4) add it to the list of squares\n",
    "                squares.append(im_sub)\n",
    "                \n",
    "            \n",
    "            # Once we have <batch_size> worth of squares in the list, fit them using the model\n",
    "            if (i % batch_size == 0) & (i != 0) & (len(squares) != 0):\n",
    "\n",
    "                outputs_sub = network(torch.stack(squares))\n",
    "                outputs_sub = torch.reshape(outputs_sub, (-1,))\n",
    "                # Append the model prediction values onto the list of outputs\n",
    "                outputs += list(outputs_sub.detach().cpu().numpy().flatten())\n",
    "\n",
    "                # Reset the list of squares\n",
    "                squares = [] \n",
    "\n",
    "        # Fit the last group of squares too, but only if theres something there\n",
    "        if len(squares) != 0:\n",
    "        \n",
    "            outputs_sub = network(torch.stack(squares))\n",
    "            outputs_sub = torch.reshape(outputs_sub, (-1,))\n",
    "            outputs += list(outputs_sub.detach().cpu().numpy().flatten())\n",
    "\n",
    "            squares = [] \n",
    "\n",
    "        # Save memory\n",
    "        del network \n",
    "        \n",
    "        now2 = time.time()\n",
    "        print('Time taken to predict squares is ' + str(now2-then2))\n",
    "\n",
    "        ################## Finally, reform the model predictions into the correct shape of the original\n",
    "        ################## data by taking into account which values should be masked\n",
    "        z = outputs\n",
    "        z = np.array(z)\n",
    "        \n",
    "        z_out = []\n",
    "        j = 0\n",
    "        # If a value was masked, then it's a zero. Otherwise, it was predicted using the model\n",
    "        for i in range(len(masked_value_tracker)):\n",
    "            if masked_value_tracker[i] == 0:\n",
    "                z_out.append(0)\n",
    "            else:\n",
    "                z_out.append(z[j])\n",
    "                j += 1\n",
    "\n",
    "        z_out = np.array(z_out)\n",
    "        z_out = z_out.reshape((y_range,x_range))\n",
    "\n",
    "        # Save the predictions as a numpy array\n",
    "        np.save(npy_dir + name + '_model_' + model_name + '.npy', z_out)\n",
    "    \n",
    "\n",
    "    # Save memory\n",
    "    del im\n",
    "\n",
    "\n",
    "now = time.time()\n",
    "print('Total time taken is ' + str(now-then))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcfb9e5",
   "metadata": {},
   "source": [
    "# Collagen Painting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2867aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "\n",
    "# Lists tracking the correlations between STIFMap/GFP/DAPI and stain intensity \n",
    "z_stain1_pearson = []\n",
    "z_stain1_spearman = []\n",
    "z_stain2_pearson = []\n",
    "z_stain2_spearman = []\n",
    "\n",
    "gfp_stain1_pearson = []\n",
    "gfp_stain1_spearman = []\n",
    "gfp_stain2_pearson = []\n",
    "gfp_stain2_spearman = []\n",
    "\n",
    "dapi_stain1_pearson = []\n",
    "dapi_stain1_spearman = []\n",
    "dapi_stain2_pearson = []\n",
    "dapi_stain2_spearman = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "045a8574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0040\n",
      "7\n",
      "time taken is 189.12568759918213\n",
      "time taken is 220.97705483436584\n",
      "Time taken is 264.7481904029846\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "then = time.time()\n",
    "\n",
    "for index in range(1):#len(dapis)):\n",
    "    #for index, row in sample_list.iterrows():\n",
    "    \n",
    "    name = names[index]\n",
    "    print(name)\n",
    "\n",
    "\n",
    "\n",
    "    #############################################################################\n",
    "    ########################################## Load the STIFFMap\n",
    "    #############################################################################\n",
    "    # Load all of the models\n",
    "    z1 = np.load(npy_dir + name + '_model_1010.npy')\n",
    "    z2 = np.load(npy_dir + name + '_model_1011.npy')\n",
    "    z3 = np.load(npy_dir + name + '_model_1012.npy')\n",
    "    z4 = np.load(npy_dir + name + '_model_1013.npy')\n",
    "    z5 = np.load(npy_dir + name + '_model_1014.npy')\n",
    "    z = np.mean(np.stack([z1,z2,z3,z4,z5]), axis=0)\n",
    "\n",
    "    ##### Get the min and max regions of the original STIFMap (not resized)\n",
    "    z_range = z.flatten()\n",
    "    # Remove masked regions\n",
    "    z_range = [i for i in z_range if i != 0]\n",
    "    z_min = min(z_range)\n",
    "    z_max = max(z_range)\n",
    "\n",
    "    y_range = z.shape[0]\n",
    "    x_range = z.shape[1]\n",
    "\n",
    "    # Read in the images\n",
    "    gfp = io.imread(staining_dir + gfps[index])\n",
    "    mask = io.imread(staining_dir + masks[index])\n",
    "    dapi = io.imread(staining_dir + dapis[index])\n",
    "    stain1 = io.imread(staining_dir + stain1s[index])\n",
    "    stain2 = io.imread(staining_dir + stain2s[index])\n",
    "    \n",
    "\n",
    "    #############################################################################\n",
    "    ########################################## Reduce to remove regions not sampled with the STIFMap\n",
    "    #############################################################################\n",
    "    gfp = gfp[half_side - half_step : (y_range-1)*step + half_side + half_step,\n",
    "         half_side - half_step : (x_range-1)*step + half_side + half_step]\n",
    "    mask = mask[half_side - half_step : (y_range-1)*step + half_side + half_step,\n",
    "         half_side - half_step : (x_range-1)*step + half_side + half_step]\n",
    "    dapi = dapi[half_side - half_step : (y_range-1)*step + half_side + half_step,\n",
    "         half_side - half_step : (x_range-1)*step + half_side + half_step]\n",
    "\n",
    "    stain1 = stain1[half_side - half_step : (y_range-1)*step + half_side + half_step,\n",
    "         half_side - half_step : (x_range-1)*step + half_side + half_step]\n",
    "\n",
    "    stain2 = stain2[half_side - half_step : (y_range-1)*step + half_side + half_step,\n",
    "         half_side - half_step : (x_range-1)*step + half_side + half_step]\n",
    "    \n",
    "\n",
    "    #############################################################################\n",
    "    ########################################## Interpolate the stiffmap to make it the same dimensions as the GFP image\n",
    "    #############################################################################\n",
    "    x = np.arange(half_step, x_range*step+half_step, step)\n",
    "    y = np.arange(half_step, y_range*step+half_step, step)\n",
    "\n",
    "    f = interpolate.interp2d(x, y, z, kind='cubic')\n",
    "\n",
    "    xnew = np.arange(0,mask.shape[1],1) #np.arange(0,y_range*step,1)\n",
    "    ynew = np.arange(0,mask.shape[0],1) #np.arange(0,x_range*step,1)\n",
    "    znew = f(xnew, ynew)\n",
    "    # Clip to remove negative values\n",
    "    znew = np.clip(znew, 0, 100000)\n",
    "    \n",
    "    #############################################################################\n",
    "    ########################################## Mask out empty regions\n",
    "    #############################################################################\n",
    "    ###### Normalize inputs\n",
    "    stain1 = norm_pic(stain1)\n",
    "    stain2 = norm_pic(stain2)\n",
    "    gfp = norm_pic(gfp)\n",
    "    mask = norm_pic(mask)\n",
    "    dapi = norm_pic(dapi)\n",
    "\n",
    "    \n",
    "    '''\n",
    "    #############################################################################\n",
    "    ########################################## Downsample\n",
    "    ############ (scale_percent can be used to downsample the image if the full image uses too much memory)\n",
    "    #############################################################################\n",
    "    # Find the new dimensions    \n",
    "    width = int(dapi.shape[1] * scale_percent / 100)\n",
    "    height = int(dapi.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "\n",
    "    # Downsample the images\n",
    "    dapi = cv2.resize(dapi, dim, interpolation = cv2.INTER_AREA)\n",
    "    gfp = cv2.resize(gfp, dim, interpolation = cv2.INTER_AREA)\n",
    "    stain1 = cv2.resize(stain1, dim, interpolation = cv2.INTER_AREA)\n",
    "    stain2 = cv2.resize(stain2, dim, interpolation = cv2.INTER_AREA)\n",
    "    znew = cv2.resize(znew, dim, interpolation = cv2.INTER_AREA)\n",
    "    mask = cv2.resize(mask, dim, interpolation = cv2.INTER_AREA)\n",
    "    '''\n",
    "\n",
    "    \n",
    "    \n",
    "    ############################# Collagen paint\n",
    "    \n",
    "    # Mask out unused regions\n",
    "    znew = znew * mask\n",
    "    gfp = gfp * mask\n",
    "    #del mask\n",
    "\n",
    "    # Clip znew to only include the stiffness range in the original STIFMap\n",
    "    znew_color = np.clip(znew, z_min, z_max)\n",
    "    #del znew\n",
    "\n",
    "    # Get the scaled image in RGB                 \n",
    "    gfp3 = np.stack([gfp,gfp,gfp], axis=2)\n",
    "    #del gfp\n",
    "    # How many colors do we want to use\n",
    "    n_colors=1000\n",
    "    hues = sns.color_palette(\"viridis\", n_colors+1)\n",
    "\n",
    "    # For every pixel, get the index of the hue we want to use\n",
    "    hue_indices = (n_colors * (znew_color - z_min) / (z_max - z_min)).astype(int)\n",
    "    hues = np.array(hues)\n",
    "\n",
    "    # Take the hue for each pixel and multiply by the intensity of the GFP image to get the final output\n",
    "    znew_color = np.take(hues, hue_indices, axis=0)\n",
    "    del hue_indices\n",
    "\n",
    "    gfp_colored = gfp3 * znew_color\n",
    "    del gfp3\n",
    "    del znew_color\n",
    "\n",
    "\n",
    "    plt.imsave(out_dir + name + '_STIFMap.png', gfp_colored)\n",
    "    del gfp_colored\n",
    "\n",
    "\n",
    "    ######### Save the colorbar\n",
    "    a = np.array([[z_min,z_max]])\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    img = plt.imshow(a, cmap=\"viridis\")\n",
    "    plt.gca().set_visible(False)\n",
    "    cax = plt.axes([0.1, 0.2, 0.1, 0.6])\n",
    "    cbar = plt.colorbar(orientation=\"vertical\", cax=cax)\n",
    "    cbar.ax.set_ylabel('log(elasticity) (Pa)', fontsize=18)\n",
    "    plt.savefig(out_dir + name + \"_colorbar.png\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ########################################### Evaluate the correlations between different signals    \n",
    "    \n",
    "    dapi = dapi.flatten()\n",
    "    gfp = gfp.flatten()\n",
    "    stain1 = stain1.flatten()\n",
    "    stain2 = stain2.flatten()\n",
    "    znew = znew.flatten()\n",
    "    mask = mask.flatten()\n",
    "    \n",
    "    df = np.zeros((len(gfp),6))\n",
    "\n",
    "    df[:,0] = dapi\n",
    "    df[:,1] = gfp\n",
    "    df[:,2] = stain1\n",
    "    df[:,3] = stain2\n",
    "    df[:,4] = znew\n",
    "    df[:,5] = mask\n",
    "\n",
    "    del dapi\n",
    "    del gfp\n",
    "    del stain1\n",
    "    del stain2\n",
    "    del znew\n",
    "    del mask\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(df)\n",
    "    df.columns = ['dapi','gfp','stain1','stain2','z','mask']\n",
    "    \n",
    "    # Remove regions that are masked out\n",
    "    df = df.loc[df['mask'] > .2]\n",
    "     \n",
    "    #print('Correlation between z and gfp is ' +str(pearsonr(df['gfp'], df['z'])[0]))\n",
    "    \n",
    "    ######################################### Looking at 99th stain percentiles for each z interval\n",
    "    samples.append(name)\n",
    "    \n",
    "    z_min = int(np.min(df['z'])*100)\n",
    "    z_max = int((np.max(df['z'])*100)+1)\n",
    "\n",
    "    intervals = np.array(range(z_min,z_max,1))/100\n",
    "\n",
    "    stain1_tracker = []\n",
    "    stain2_tracker = []\n",
    "    intervals_used = []\n",
    "\n",
    "    for interval in intervals:\n",
    "        df_sub = df.loc[df['z'] < interval + .01].loc[df['z'] > interval]\n",
    "        if df_sub.shape[0] != 0:\n",
    "            stain1_tracker.append(np.quantile(df_sub['stain1'], .99))\n",
    "            stain2_tracker.append(np.quantile(df_sub['stain2'], .99))\n",
    "            intervals_used.append(interval)\n",
    "\n",
    "    z_stain1_pearson.append(pearsonr(intervals_used, stain1_tracker))\n",
    "    z_stain2_pearson.append(pearsonr(intervals_used, stain2_tracker))\n",
    "    z_stain1_spearman.append(spearmanr(intervals_used, stain1_tracker))\n",
    "    z_stain2_spearman.append(spearmanr(intervals_used, stain2_tracker))\n",
    "\n",
    "    print(7)\n",
    "    now = time.time()\n",
    "    print('time taken is ' + str(now-then))\n",
    "    \n",
    "    ######################################### Looking at 99th stain percentiles for each gfp interval\n",
    "    intervals = np.array(range(1,100))/100\n",
    "\n",
    "    stain1_tracker = []\n",
    "    stain2_tracker = []\n",
    "    intervals_used = []\n",
    "\n",
    "    for interval in intervals:\n",
    "        df_sub = df.loc[df['gfp'] < interval + .01].loc[df['gfp'] > interval]\n",
    "        if df_sub.shape[0] != 0:\n",
    "            stain1_tracker.append(np.quantile(df_sub['stain1'], .99))\n",
    "            stain2_tracker.append(np.quantile(df_sub['stain2'], .99))\n",
    "            intervals_used.append(interval)\n",
    "\n",
    "    gfp_stain1_pearson.append(pearsonr(intervals_used, stain1_tracker))\n",
    "    gfp_stain2_pearson.append(pearsonr(intervals_used, stain2_tracker))\n",
    "    gfp_stain1_spearman.append(spearmanr(intervals_used, stain1_tracker))\n",
    "    gfp_stain2_spearman.append(spearmanr(intervals_used, stain2_tracker))\n",
    "\n",
    "\n",
    "    now = time.time()\n",
    "    print('time taken is ' + str(now-then))\n",
    "    \n",
    "    ######################################### Looking at 99th stain percentiles for each dapi interval\n",
    "    intervals = np.array(range(1,100))/100\n",
    "\n",
    "    stain1_tracker = []\n",
    "    stain2_tracker = []\n",
    "    intervals_used = []\n",
    "\n",
    "    for interval in intervals:\n",
    "        df_sub = df.loc[df['dapi'] < interval + .01].loc[df['dapi'] > interval]\n",
    "        if df_sub.shape[0] != 0:\n",
    "            stain1_tracker.append(np.quantile(df_sub['stain1'], .99))\n",
    "            stain2_tracker.append(np.quantile(df_sub['stain2'], .99))\n",
    "            intervals_used.append(interval)\n",
    "\n",
    "    dapi_stain1_pearson.append(pearsonr(intervals_used, stain1_tracker))\n",
    "    dapi_stain2_pearson.append(pearsonr(intervals_used, stain2_tracker))\n",
    "    dapi_stain1_spearman.append(spearmanr(intervals_used, stain1_tracker))\n",
    "    dapi_stain2_spearman.append(spearmanr(intervals_used, stain2_tracker))\n",
    "    \n",
    "    \n",
    "    \n",
    "    del df\n",
    "    \n",
    "    \n",
    "    now = time.time()\n",
    "    print('Time taken is ' + str(now-then))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ae028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da9e357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05ed158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb86ce0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1c4c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
